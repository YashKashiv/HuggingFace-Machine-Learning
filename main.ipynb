{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Hey You are Very Rude Go Away From my Eyesight and Never Come Back Because if You Comeback i Will Not Open the Main Door',\n",
       " 'labels': ['Rudeness',\n",
       "  'Negative',\n",
       "  'Angry',\n",
       "  'Sad',\n",
       "  'Positive',\n",
       "  'Neutral',\n",
       "  'Happy'],\n",
       " 'scores': [0.7018026113510132,\n",
       "  0.1930292695760727,\n",
       "  0.0897936001420021,\n",
       "  0.012113158591091633,\n",
       "  0.0012727489229291677,\n",
       "  0.0012051165103912354,\n",
       "  0.0007834628922864795]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "classifier(\"Hey You are Very Rude Go Away From my Eyesight and Never Come Back Because if You Comeback i Will Not Open the Main Door\", candidate_labels = [\"Positive\", \"Negative\", \"Neutral\",\"Happy\", \"Sad\", \"Angry\", \"Rudeness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hey I was waiting for last night but you all were ready to go down and have the party at one of his places just now...\\n\\n[22:03] You all were so ready for the party at the park that they called your mother'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "\n",
    "generator(\"Hey I was waiting for last night but you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hi I saw you at stage you were awesome and you were fantastic.\\nYou gave me some advice on running and how easy it is to do this:\\nStart with a warm up/maintain it, and then start with the following,\\n\\n'},\n",
       " {'generated_text': \"Hi I saw you at stage you were awesome and it is very sweet.\\n\\nI'm glad you did so and it's a blast to have that on your hands and even if i am not going to do anything more than just throw up to\"},\n",
       " {'generated_text': 'Hi I saw you at stage you were awesome and I enjoyed it.\\nYou could read it on my blog and in the comments below. Thanks for reading. If you are lucky I can also be one to see you in the upcoming release of C'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "\n",
    "generator(\"Hi I saw you at stage you were awesome and\", max_length = 50, num_return_sequences = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.06264451891183853,\n",
       "  'token': 15049,\n",
       "  'token_str': ' sunshine',\n",
       "  'sequence': 'My face shines always because of sunshine.'},\n",
       " {'score': 0.038252510130405426,\n",
       "  'token': 24,\n",
       "  'token_str': ' it',\n",
       "  'sequence': 'My face shines always because of it.'},\n",
       " {'score': 0.030583450570702553,\n",
       "  'token': 20843,\n",
       "  'token_str': ' sunlight',\n",
       "  'sequence': 'My face shines always because of sunlight.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "\n",
    "unmasker(\"My face shines always because of <mask>.\", top_k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.99728936,\n",
       "  'word': 'Yash',\n",
       "  'start': 11,\n",
       "  'end': 15},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9924481,\n",
       "  'word': 'AllHeartWeb',\n",
       "  'start': 30,\n",
       "  'end': 41},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99629503,\n",
       "  'word': 'Chandigarh',\n",
       "  'start': 63,\n",
       "  'end': 73}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Named entity recognition (NER) is a natural language processing (NLP) method that extracts information from text.\n",
    "NER involves detecting and categorizing important information in text known as named entities.'''\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities = True)\n",
    "\n",
    "ner(\"My name is Yash and I work at AllHeartWeb as Data Scientist in Chandigarh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.7338512539863586, 'start': 30, 'end': 41, 'answer': 'AllHeartWeb'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "\n",
    "question_answerer(question = \"where do i work ?\", context = \"My name is Yash and I work at AllHeartWeb as Data Scientist in Chandigarh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \" India's Prime Minister Narendra Modi seeks a third term in the parliamentary elections beginning next month . Modi has redefined India’s identity on the world stage from a secular democracy to a Hindu civilizational state . India's ongoing spat with the Maldives resulted in widespread calls in India for an economic boycott of that country . Indians and people of Indian descent overseas have long helped champion policies favorable to New Delhi .\"}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "summarizer(\"As India’s Prime Minister Narendra Modi seeks a third term in the parliamentary elections beginning next month, his electoral campaign will be predicated on the many ways in which he has transformed India during his decade in power.Foreign policy is almost never a part of India’s electoral discourse, but Modi has been an exception. In the run-up to the campaign trail, his party, the Bharatiya Janata Party (BJP), has highlighted Modi’s slogan of positioning India as a “vishwaguru” or world leader. That term was debuted prominently on the world stage when India hosted the G-20 last year; imposing banners of Modi and the G-20’s sundry meetings were then erected across the country.Modi’s energetic popularization of foreign policy in India’s public discourse is a stark departure from the past, when foreign policy events were largely unknown beyond the corridors and chancelleries of New Delhi. This wider involvement of the public would be welcome if it sparked informed debate, transparency, and accountability for foreign policy outcomes. But amid communal polarization and declining press freedom, public discourse has only complicated India’s relations with sundry countries, particularly in the neighborhood.Take India’s ongoing spat with the Maldives. Early this year, the Maldives asked New Delhi to withdraw Indian troops from its strategically significant islands. That culmination was reached after political leaders, celebrities, and journalists in India reacted angrily to derogatory comments about Modi by three Maldivian ministers. The Maldivian government suspended the ministers in question, but that did little to prevent widespread calls in India for an economic boycott of that country. As a result, Indian tourist arrivals in the Maldives have fallen considerably in recent months.In line with this popularization of foreign policy, Modi has redefined India’s identity on the world stage from a secular democracy to a Hindu civilizational state.For decades, India had portrayed itself as the poster boy of liberal democracy in the developing world. Under previous regimes, New Delhi had showcased India’s syncretic, multi-religious culture, and its unique ability to foster and embrace diversity while its neighbors descended into civil wars and communal chaos.But Modi has used foreign policy to espouse Hindu nationalist causes almost exclusively: the export of ancient Hindu culture, the erasure of Islamic art and history, and the inauguration of Hindu temples abroad.That has also changed the nature of India’s diaspora, with far-reaching implications. Indians and people of Indian descent overseas make up the largest diaspora of any country in the world, and they have long helped champion policies favorable to New Delhi. Most notably, in the 2000s, after India faced sanctions for its nuclear tests, diaspora groups lobbied to build global legitimacy for India as a nuclear power. That resulted in the landmark nuclear deal between India and the United States and pushed countries like Australia to reconsider nuclear export bans.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"My name is Yash and I'm a data scientist.\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# translating from french to english\n",
    "# pip install sentencepiece\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model = \"Helsinki-NLP/opus-mt-fr-en\")\n",
    "\n",
    "translator(\"Je m'appelle Yash et je suis data scientist.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
